<h1 align="center"> Medical-Insurance-Prediction-Data-Science-Project </h1>

## Table of contents
* [Problem Statement](#problem-statement)
* [Data Source](#data-sources)
* [Technologies](#technologies)
* [Setup](#setup)
* [Project Pipeline](#project-pipeline)

## Problem Statement
<br>
the purpose of this data is to look into the different features 
to observe their relationship, ML model based on several features 
of individuals such as age, physical/family condition and location 
against their existing medical expense to be used for predicting
future medical expenses of individuals that help medical insurance 
to make decision on charging the premium.
<br>

## Data Source
<br>

Kaggle link : "https://www.kaggle.com/datasets/noordeen/insurance-premium-prediction"

<br>

## Technologies

* Python
* Machine Learning
* MongoDB Database
* Docker
* Git
* Streamlit

<br>

## Setup 

To install requirement file
```
pip install -r requirements.txt
```

* Add files to git  `git add .` or  `git add <file_name>`    
* To check the git status  `git status`    
* To check all version maintained by git  `git log`    
* To create version/commit all changes by git  `git commit -m "message"`    
* To send version/changes to github  `git push origin main`

<br>

## Project Pipeline

1. [Data Ingestion](#1-data-ingestion)
2. [Data Validation](#2-data-validation)
3. [Data Transformation](#3-data-transformation)
4. [Model Training](#4-model-training)
5. [Model Evaluation](#5-model-evaluation)
6. [Model Deployement](#6-model-deployement)

<br>

### 1. Data Ingestion: 
* Data ingestion is the process in which unstructured data is extracted from one or multiple sources and then prepared for training machine learning models.

<br>

### 2. Data Validation:
* Data validation is an integral part of ML pipeline. It is checking the quality of source data before training a new mode
* It focuses on checking that the statistics of the new data are as expected (e.g. feature distribution, number of categories, etc). 

<br>

### 3. Data Transformation 
* Data transformation is the process of converting raw data into a format or structure that would be more suitable for model building.
* It is an imperative step in feature engineering that facilitates discovering insights.

<br>

### 4. Model Training
* Model training in machine learning is the process in which a machine learning (ML) algorithm is fed with sufficient training data to learn from.

<br>

### 5. Model Evaluation
* Model evaluation is the process of using different evaluation metrics to understand a machine learning modelâ€™s performance, as well as its strengths and weaknesses.
* Model evaluation is important to assess the efficacy of a model during initial research phases, and it also plays a role in model monitoring.

<br>

### 6. Model Deployement
* Deployment is the method by which we integrate a machine learning model into production environment to make practical business decisions based on data. 

<br>

<br><br><br>
### Thanks & Regards
### Nilutpal Das